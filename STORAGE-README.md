# ğŸ’¾ Metadata Storage System

## ğŸ“Š How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. User Uploads Excel/CSV                              â”‚
â”‚     POST /upload/ingest                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Parse & Enhance    â”‚
        â”‚  - Excel/CSV Parser â”‚
        â”‚  - PK/FK Heuristics â”‚
        â”‚  - LLM Analysis     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Save to Disk       â”‚
        â”‚  artifacts/         â”‚
        â”‚    â””â”€â”€ <fileId>/    â”‚
        â”‚        â””â”€â”€ metadata.json  â† ALL 711 rows here!
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Return fileId      â”‚
        â”‚  to user            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Directory Structure

```
artifacts/
â”œâ”€â”€ 1768288214005/              â† fileId (timestamp)
â”‚   â”œâ”€â”€ metadata.json           â† Source of truth!
â”‚   â”œâ”€â”€ schema.dbml             â† (Generated later)
â”‚   â”œâ”€â”€ postgres.sql            â† (Generated later)
â”‚   â”œâ”€â”€ snowflake.sql           â† (Generated later)
â”‚   â”œâ”€â”€ erd.mmd                 â† (Generated later)
â”‚   â”œâ”€â”€ erd.png                 â† (Generated later)
â”‚   â””â”€â”€ erd.svg                 â† (Generated later)
â””â”€â”€ 1768287140736/
    â””â”€â”€ metadata.json
```

---

## ğŸ“„ metadata.json Structure

```json
{
  "fileId": "1768288214005",
  "originalName": "Test-1-EY.xlsx",
  "uploadedAt": "2026-01-13T10:30:00.000Z",
  "fileSize": 162321,
  "filePath": "uploads/1768288214005_&_Test-1-EY.xlsx",
  
  "metadata": {
    "rowCount": 711,
    "tableCount": 31,
    "tables": {
      "account": {
        "tableName": "account",
        "columns": [
          {
            "columnName": "tax_reporting_contact",
            "dataType": "VARCHAR",
            "isPrimaryKey": false,
            "isForeignKey": false,
            "nullable": true,
            "_sourceRow": 77
          },
          {
            "columnName": "account_id",
            "dataType": "VARCHAR",
            "isPrimaryKey": true,
            "isForeignKey": false,
            "_pkSource": "inferred",
            "_pkConfidence": 0.85
          }
          // ... all columns for 'account' table
        ]
      },
      "employee": {
        "tableName": "employee",
        "columns": [...]
      }
      // ... all 31 tables
    }
  },
  
  "inference": {
    "primaryKeys": { "explicit": 0, "inferred": 31 },
    "foreignKeys": { "explicit": 0, "inferred": 15 }
  },
  
  "llmStatus": {
    "initialized": false,
    "provider": "Ollama",
    "modelName": "deepseek-r1:7b"
  },
  
  "artifacts": {
    "dbml": { "generated": false },
    "sql_postgres": { "generated": false },
    "sql_snowflake": { "generated": false },
    "erd_png": { "generated": false },
    "erd_svg": { "generated": false }
  },
  
  "createdAt": "2026-01-13T10:30:00.000Z"
}
```

---

## ğŸ”„ Complete Flow

### 1. Upload & Save

```bash
POST http://localhost:3000/upload/ingest
Content-Type: multipart/form-data

file: Test-1-EY.xlsx
```

**Response:**
```json
{
  "success": true,
  "message": "File uploaded, parsed, and metadata saved successfully!",
  "data": {
    "fileId": "1768288214005",
    "originalName": "Test-1-EY.xlsx",
    "metadata": {
      "rowCount": 711,
      "tableCount": 31,
      "tables": ["account", "employee", ...]
    },
    "artifacts": {
      "metadataPath": "artifacts/1768288214005/metadata.json",
      "available": ["dbml", "sql", "erd"]
    }
  }
}
```

**What Happened:**
âœ… File uploaded to `uploads/1768288214005_&_Test-1-EY.xlsx`
âœ… Parsed 711 rows, 31 tables
âœ… Applied heuristics
âœ… Saved to `artifacts/1768288214005/metadata.json`

---

### 2. Generate Artifacts (Module 5 - Coming Next)

```bash
POST http://localhost:3000/generate/dbml
Content-Type: application/json

{
  "fileId": "1768288214005"
}
```

**What Will Happen:**
1. Read `artifacts/1768288214005/metadata.json`
2. Generate DBML from metadata.tables
3. Save to `artifacts/1768288214005/schema.dbml`
4. Return DBML content

---

## ğŸ¯ Why This Works

| Benefit | Explanation |
|---------|-------------|
| **Simple** | Just JSON files on disk |
| **Fast** | No database connection needed |
| **Portable** | Works anywhere |
| **Inspectable** | Open JSON in any editor |
| **Recoverable** | Copy/backup artifacts folder |
| **Demo-friendly** | Zero setup required |

---

## ğŸ“ File Operations

### Save Metadata
```javascript
import { saveMetadata } from './storage/fileStorage.js';

await saveMetadata(fileId, data);
// Saves to: artifacts/<fileId>/metadata.json
```

### Get Metadata
```javascript
import { getMetadata } from './storage/fileStorage.js';

const data = await getMetadata(fileId);
// Reads from: artifacts/<fileId>/metadata.json
```

### Save Artifact
```javascript
import { saveArtifact } from './storage/fileStorage.js';

await saveArtifact(fileId, 'dbml', content, 'schema.dbml');
// Saves to: artifacts/<fileId>/schema.dbml
```

---

## âœ… Current Status

**Implemented:**
- âœ… File storage layer (`src/storage/fileStorage.js`)
- âœ… Save metadata on upload
- âœ… Return fileId in response
- âœ… Artifacts directory auto-created

**Next (Module 5):**
- â³ Generate DBML from metadata.json
- â³ Generate SQL DDL from metadata.json
- â³ Generate ERD from metadata.json

---

## ğŸš€ Test It

1. **Start server:**
   ```bash
   npm start
   ```

2. **Upload file:**
   ```bash
   curl -X POST http://localhost:3000/upload/ingest \
     -H "X-API-Key: dev-api-key-change-in-production" \
     -F "file=@test-files/Test-1-EY.xlsx"
   ```

3. **Check artifacts folder:**
   ```bash
   ls artifacts/
   # You'll see: 1768288214005/
   
   cat artifacts/1768288214005/metadata.json
   # All 711 rows stored here!
   ```

---

**Ready for Module 5: Artifact Generation!** ğŸ¯

